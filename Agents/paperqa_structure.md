## PaperQA main innovations
<ul>
  <li>RAG is decomposed into parts, and parts are provided as tools to an agent (they are: search, gather_evidence, answer_question). This serves the purpose of running some operations, such as web search, multiple times with different keywords in case initial attempts are unsuccessful.</li>
  <li>Map-reduced step is used. <i>Map</i> is a summarization step to gather evidence from multiple sources, and <i>reduce</i> is to generate an answer. Through this, a scratchpad is introduced, where the LLM can give intermediate evidence before formulating the final answer</li>
  <li>Relevance score is used in retrieval. The relevance score is generated by the LLM using internal LLM reasoning about how much the text chunk is relevant to the question. </li>
  <li>A priori and a posteriori prompting is used</li>
</ul>

## Structure of PaperQA
<ul>
  <li>core.py</li>
  <li>docs.py</li>
  <li>litqa.py</li>
  <li>llms.py</li>
  <li>paths.py</li>
  <li>prompts.py</li>
  <li>rate_limiter.py</li>
  <li>readers.py</li>
  <li>settings.py</li>
  <li>types.py</li>
  <li>utils.py</li>
  <li>py.typed</li>
  <li>agents</li>
  <ul>
    <li>main.py</li>
    <li>models.py</li>
    <li>search.py</li>
    <li>tasks.py</li>
    <li>tools.py</li>
    <li>helpers.py</li>
    <li>env.py</li>
  </ul>
  <li>clients</li>
  <ul>
    <li>client_models.py</li>
    <li>crossref.py</li>
    <li>exceptions.py</li>
    <li>journal_quality.py</li>
    <li>openalex.py</li>
    <li>retractions.py</li>
    <li>semantic_scholar.py</li>
    <li>unpaywall.py</li>
    <li>client_data</li>
  </ul>
  <li>configs</li>
  <li><b>contrib</b>b</li>
  <ul>
    <li><b>zotero.py</b>: This module gets PDF files from the user's Zotero library</li>
  </ul>
</ul>
